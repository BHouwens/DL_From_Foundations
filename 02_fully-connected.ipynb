{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "02_fully-connected.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCtWCP44mKgb"
      },
      "source": [
        "# **Forward and Backward Passes**\n",
        "\n",
        "In this notebook we'll be looking at setting up the forward and backward passes for the fully connected model architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPFZCnLOmKgc"
      },
      "source": [
        "## **Colab Setup**\n",
        "The setup structure for this will depend on the environment. I'm assuming a Google Colab environment in this case, which will require the following setup from the Github repo, and assumes that the repo has already been cloned into Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDmZQwIumKgc",
        "outputId": "cbc18449-5acf-4f8d-f538-321283013fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/git_folder/DL_From_Foundations\n",
        "! git pull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/git_folder/DL_From_Foundations\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/BHouwens/DL_From_Foundations\n",
            "   e9806a4..ad10e4f  main       -> origin/main\n",
            "Updating e9806a4..ad10e4f\n",
            "Fast-forward\n",
            " 02_fully-connected.ipynb | 299 \u001b[32m++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-----------\u001b[m\n",
            " 1 file changed, 234 insertions(+), 65 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMmocQeRmKgd"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9iw4ro3me4H"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzxcMn7bnga6"
      },
      "source": [
        "## **Normalize Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvIkv233mgRH"
      },
      "source": [
        "#export\n",
        "from exp.nb_01 import *\n",
        "from keras.datasets import mnist\n",
        "\n",
        "def get_data():\n",
        "    # Load the data into the train and validation sets\n",
        "    (x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
        "\n",
        "    # Map the sets to tensors\n",
        "    x_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "    # Flatten the 28 * 28 to match the course\n",
        "    x_train = torch.flatten(x_train, 1)\n",
        "    x_valid = torch.flatten(x_valid, 1)\n",
        "\n",
        "    return x_train, x_valid, y_train, y_valid\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeJ259KqmhH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb633f0-98da-46e1-a375-3b36320be604"
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()\n",
        "\n",
        "train_mean,train_std = x_train.float().mean(),x_train.float().std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(33.3184), tensor(78.5675))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5t42BXsmoWR"
      },
      "source": [
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "\n",
        "# NB: Use training, not validation mean for validation set\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTkcKoa_nphE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f06a976-961f-42d3-b26e-d7ae3feec289"
      },
      "source": [
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.8892e-08), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aloZ-9BpTs7",
        "outputId": "deecae9d-a51f-42f2-e27b-9e1daf847281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's check out the shapes\n",
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "n,m,c"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784, tensor(0, dtype=torch.uint8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMTTKCeHszr9",
        "outputId": "b2eb2c8a-3e09-41b7-fda5-7ed2f50df048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_valid.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXjCqvR8nxjR"
      },
      "source": [
        "Now we're talking!\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdNdle8vn68P"
      },
      "source": [
        "## **Foundations (v1.0)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY9KNaxJn-g7"
      },
      "source": [
        "# num hidden nodes\n",
        "nh = 50"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JubbMP7oosSP"
      },
      "source": [
        "# 2 layers, so we need 2 weights and 2 biases\n",
        "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMrlBo7bpX7H"
      },
      "source": [
        "def linear_layer(x, w, b):\n",
        "  return x@w + b"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFu9iYr5prZ4"
      },
      "source": [
        "t = linear_layer(x_valid, w1, b1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQW-mKc0p08Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}