{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0821eb00"
   },
   "source": [
    "# **Matrix Multiplication from the Foundations**\n",
    "\n",
    "This notebook will setup all our required matrix multiplication code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRlcNYzz1Vze"
   },
   "source": [
    "## **Colab Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjjnCKH11X0l"
   },
   "source": [
    "The setup structure for this will depend on the environment. I'm assuming a Google Colab environment in this case, which will require the following setup from the Github repo, and assumes that the repo has already been cloned into Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lizDqMGP1Aj2",
    "outputId": "ca392385-d63f-4863-adfe-f23eb5763741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/git_folder/DL_From_Foundations\n",
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 6 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (6/6), done.\n",
      "From https://github.com/BHouwens/DL_From_Foundations\n",
      "   91f7e9c..ce3d8b6  main       -> origin/main\n",
      "Updating 91f7e9c..ce3d8b6\n",
      "Fast-forward\n",
      " 01_matrix-mul.ipynb | 600 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--------\u001b[m\n",
      " 1 file changed, 515 insertions(+), 85 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "%cd gdrive/My Drive/git_folder/DL_From_Foundations\n",
    "! git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dd706ed"
   },
   "source": [
    "## **Testing Imports**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBrdR_af2PMC"
   },
   "source": [
    "This section is to test outputs from notebook to Python script conversion. It's not necessary to run this stuff if imports are going to be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6fdf1a03"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1e8b00d1"
   },
   "outputs": [],
   "source": [
    "from exp.nb_0 import *\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJUw4f9amlRn"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_eq(a,b): test(a,b,operator.eq,'==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ea033ba"
   },
   "source": [
    "A simple test can be run using this little unit test util. Example with the `TEST` output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20ec798d"
   },
   "outputs": [],
   "source": [
    "test_eq(TEST,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQUZ0Iui74DX"
   },
   "source": [
    "And another test using `pretty_log`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2j934h479es",
    "outputId": "093dbdb4-3590-42b6-a269-32931b574c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m#==== Hello World ====#\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_log(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06e6b85d"
   },
   "outputs": [],
   "source": [
    "# To run tests in console:\n",
    "# !python3 run_notebook.py 01_matrix-mul.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaFo4jvolxmM"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0863fd78"
   },
   "source": [
    "\n",
    "## **Getting the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e517ee32"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "MNIST_URL='https://ndownloader.figshare.com/files/25635053'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32f97109"
   },
   "source": [
    "Now we can try to download the MNIST dataset through the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d15ad28",
    "outputId": "6eb2493c-785c-4ada-8285-ffd8bfa9150f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ndownloader.figshare.com/files/25635053.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/.fastai/data/25635053.gz')"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = datasets.download_data(MNIST_URL, ext='.gz'); path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWzrKePV2rot"
   },
   "source": [
    "Once the data has been downloaded we can unzip and check it out in tensor form. Note that Pytorch tensors follow very much the Numpy array structure and utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spu7TCbr20of",
    "outputId": "e0f4e0b4-dbce-473b-b158-c0e0c4a95e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "\u001b[34m#==== X train data ====#\u001b[0m\n",
      "\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0], dtype=torch.uint8)\n",
      "60000\n",
      "\n",
      "\u001b[34m#==== Y vector dependent ====#\u001b[0m\n",
      "\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8], dtype=torch.uint8)\n",
      "torch.Size([60000])\n",
      "\n",
      "\u001b[34m#==== Y min ====#\u001b[0m\n",
      "\n",
      "tensor(0, dtype=torch.uint8)\n",
      "\n",
      "\u001b[34m#==== Y max ====#\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(9, dtype=torch.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load the data into the train and validation sets\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
    "\n",
    "# Map the sets to tensors\n",
    "x_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "# Flatten the 28 * 28 to match the course\n",
    "x_train = torch.flatten(x_train, 1)\n",
    "x_valid = torch.flatten(x_valid, 1)\n",
    "\n",
    "n, c = x_train.shape\n",
    "\n",
    "# Let's see the shapes\n",
    "pretty_log(\"X train data\")\n",
    "print(x_train[0][:28])\n",
    "print(n)\n",
    "\n",
    "pretty_log(\"Y vector dependent\")\n",
    "print(y_train)\n",
    "print(y_train.shape) \n",
    "\n",
    "pretty_log(\"Y min\")\n",
    "print(y_train.min())\n",
    "\n",
    "pretty_log(\"Y max\")\n",
    "y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5rStTdH8SnE"
   },
   "outputs": [],
   "source": [
    "# Let's unit test our expectations\n",
    "assert n==y_train.shape[0]==60000\n",
    "test_eq(c1,28)\n",
    "test_eq(c2,28)\n",
    "test_eq(y_train.min(),0)\n",
    "test_eq(y_train.max(),9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMzyJCd89IlA"
   },
   "source": [
    "We'll set the colour map here and take a look at a sample from our training set. Colourmaps in Matplotlib are often split into several categories based on their function:\n",
    "\n",
    "*   **Sequential**: change in lightness and often saturation of color incrementally, often using a single hue; should be used for representing information that has ordering.\n",
    "\n",
    "*   **Diverging**: change in lightness and possibly saturation of two different colors that meet in the middle at an unsaturated color; should be used when the information being plotted has a critical middle value, such as topography or when the data deviates around zero.\n",
    "\n",
    "*   **Cyclic**: change in lightness of two different colors that meet in the middle and beginning/end at an unsaturated color; should be used for values that wrap around at the endpoints, such as phase angle, wind direction, or time of day.\n",
    "\n",
    "*   **Qualitative**: often are miscellaneous colors; should be used to represent information which does not have ordering or relationships.\n",
    "\n",
    "More info on which `image.cmap` value corresponds to which function can be found in the Matplotlib docs [here](https://matplotlib.org/stable/tutorials/colors/colormaps.html). We'll set this one to `gray`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKq27z9V9xqS"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f8H5wEQ90UO"
   },
   "source": [
    "Okay finally on to the training set sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "DZeBBBnP8fXh",
    "outputId": "58423f3b-d526-433a-c47c-5b48d47089f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.ByteTensor\n",
      "\n",
      "\u001b[34m#==== Image sample ====#\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN9klEQVR4nO3df4xV9ZnH8c+zWP6QojBrOhKKSyEGg8ZON4gbl6w1hvojGhw1TSexoZE4/YNJaLIhNewf1WwwZBU2SzTNTKMWNl1qEzUgaQouoOzGhDgiKo5LdQ2mTEaowZEf/mCHefaPezBTnfu9w7nn3nOZ5/1Kbu6957nnnicnfDi/7pmvubsATH5/VXYDAJqDsANBEHYgCMIOBEHYgSAuaubCzIxT/0CDubuNN72uLbuZ3Wpmh8zsPTN7sJ7vAtBYlvc6u5lNkfRHSUslHZH0qqQudx9IzMOWHWiwRmzZF0t6z93fd/czkn4raVkd3weggeoJ+2xJfxrz/kg27S+YWbeZ9ZtZfx3LAlCnhp+gc/c+SX0Su/FAmerZsg9KmjPm/bezaQBaUD1hf1XSlWb2HTObKulHkrYV0xaAouXejXf3ETPrkbRD0hRJT7n724V1BqBQuS+95VoYx+xAwzXkRzUALhyEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBJF7yGZcGKZMmZKsX3rppQ1dfk9PT9XaxRdfnJx3wYIFyfrKlSuT9ccee6xqraurKznv559/nqyvW7cuWX/44YeT9TLUFXYzOyzppKSzkkbcfVERTQEoXhFb9pvc/aMCvgdAA3HMDgRRb9hd0k4ze83Musf7gJl1m1m/mfXXuSwAdah3N36Juw+a2bckvWhm/+Pue8d+wN37JPVJkpl5ncsDkFNdW3Z3H8yej0l6XtLiIpoCULzcYTezaWY2/dxrST+QdLCoxgAUq57d+HZJz5vZue/5D3f/QyFdTTJXXHFFsj516tRk/YYbbkjWlyxZUrU2Y8aM5Lz33HNPsl6mI0eOJOsbN25M1js7O6vWTp48mZz3jTfeSNZffvnlZL0V5Q67u78v6bsF9gKggbj0BgRB2IEgCDsQBGEHgiDsQBDm3rwftU3WX9B1dHQk67t3707WG32baasaHR1N1u+///5k/dSpU7mXPTQ0lKx//PHHyfqhQ4dyL7vR3N3Gm86WHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeC4Dp7Adra2pL1ffv2Jevz5s0rsp1C1ep9eHg4Wb/pppuq1s6cOZOcN+rvD+rFdXYgOMIOBEHYgSAIOxAEYQeCIOxAEIQdCIIhmwtw/PjxZH316tXJ+h133JGsv/7668l6rT+pnHLgwIFkfenSpcn66dOnk/Wrr766am3VqlXJeVEstuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EAT3s7eASy65JFmvNbxwb29v1dqKFSuS8953333J+pYtW5J1tJ7c97Ob2VNmdszMDo6Z1mZmL5rZu9nzzCKbBVC8iezG/1rSrV+Z9qCkXe5+paRd2XsALaxm2N19r6Sv/h50maRN2etNku4quC8ABcv72/h2dz83WNaHktqrfdDMuiV151wOgILUfSOMu3vqxJu790nqkzhBB5Qp76W3o2Y2S5Ky52PFtQSgEfKGfZuk5dnr5ZK2FtMOgEapuRtvZlskfV/SZWZ2RNIvJK2T9DszWyHpA0k/bGSTk92JEyfqmv+TTz7JPe8DDzyQrD/zzDPJeq0x1tE6aobd3buqlG4uuBcADcTPZYEgCDsQBGEHgiDsQBCEHQiCW1wngWnTplWtvfDCC8l5b7zxxmT9tttuS9Z37tyZrKP5GLIZCI6wA0EQdiAIwg4EQdiBIAg7EARhB4LgOvskN3/+/GR9//79yfrw8HCyvmfPnmS9v7+/au2JJ55IztvMf5uTCdfZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIrrMH19nZmaw//fTTyfr06dNzL3vNmjXJ+ubNm5P1oaGhZD0qrrMDwRF2IAjCDgRB2IEgCDsQBGEHgiDsQBBcZ0fSNddck6xv2LAhWb/55vyD/fb29ibra9euTdYHBwdzL/tClvs6u5k9ZWbHzOzgmGkPmdmgmR3IHrcX2SyA4k1kN/7Xkm4dZ/q/untH9vh9sW0BKFrNsLv7XknHm9ALgAaq5wRdj5m9me3mz6z2ITPrNrN+M6v+x8gANFzesP9S0nxJHZKGJK2v9kF373P3Re6+KOeyABQgV9jd/ai7n3X3UUm/krS42LYAFC1X2M1s1pi3nZIOVvssgNZQ8zq7mW2R9H1Jl0k6KukX2fsOSS7psKSfunvNm4u5zj75zJgxI1m/8847q9Zq3StvNu7l4i/t3r07WV+6dGmyPllVu85+0QRm7Bpn8pN1dwSgqfi5LBAEYQeCIOxAEIQdCIKwA0FwiytK88UXXyTrF12Uvlg0MjKSrN9yyy1Vay+99FJy3gsZf0oaCI6wA0EQdiAIwg4EQdiBIAg7EARhB4KoedcbYrv22muT9XvvvTdZv+6666rWal1Hr2VgYCBZ37t3b13fP9mwZQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBILjOPsktWLAgWe/p6UnW77777mT98ssvP++eJurs2bPJ+tBQ+q+Xj46OFtnOBY8tOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwXX2C0Cta9ldXeMNtFtR6zr63Llz87RUiP7+/mR97dq1yfq2bduKbGfSq7llN7M5ZrbHzAbM7G0zW5VNbzOzF83s3ex5ZuPbBZDXRHbjRyT9o7svlPR3klaa2UJJD0ra5e5XStqVvQfQomqG3d2H3H1/9vqkpHckzZa0TNKm7GObJN3VqCYB1O+8jtnNbK6k70naJ6nd3c/9OPlDSe1V5umW1J2/RQBFmPDZeDP7pqRnJf3M3U+MrXlldMhxB2109z53X+Tui+rqFEBdJhR2M/uGKkH/jbs/l00+amazsvosScca0yKAItTcjTczk/SkpHfcfcOY0jZJyyWty563NqTDSaC9fdwjnC8tXLgwWX/88ceT9auuuuq8eyrKvn37kvVHH320am3r1vQ/GW5RLdZEjtn/XtKPJb1lZgeyaWtUCfnvzGyFpA8k/bAxLQIoQs2wu/t/Sxp3cHdJNxfbDoBG4eeyQBCEHQiCsANBEHYgCMIOBMEtrhPU1tZWtdbb25uct6OjI1mfN29erp6K8MorryTr69evT9Z37NiRrH/22Wfn3RMagy07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgQR5jr79ddfn6yvXr06WV+8eHHV2uzZs3P1VJRPP/20am3jxo3JeR955JFk/fTp07l6Quthyw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQYS5zt7Z2VlXvR4DAwPJ+vbt25P1kZGRZD11z/nw8HByXsTBlh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgjB3T3/AbI6kzZLaJbmkPnf/NzN7SNIDkv6cfXSNu/++xnelFwagbu4+7qjLEwn7LEmz3H2/mU2X9Jqku1QZj/2Uuz820SYIO9B41cI+kfHZhyQNZa9Pmtk7ksr90ywAztt5HbOb2VxJ35O0L5vUY2ZvmtlTZjazyjzdZtZvZv11dQqgLjV347/8oNk3Jb0saa27P2dm7ZI+UuU4/p9V2dW/v8Z3sBsPNFjuY3ZJMrNvSNouaYe7bxinPlfSdne/psb3EHagwaqFveZuvJmZpCclvTM26NmJu3M6JR2st0kAjTORs/FLJP2XpLckjWaT10jqktShym78YUk/zU7mpb6LLTvQYHXtxheFsAONl3s3HsDkQNiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQii2UM2fyTpgzHvL8umtaJW7a1V+5LoLa8ie/ubaoWm3s/+tYWb9bv7otIaSGjV3lq1L4ne8mpWb+zGA0EQdiCIssPeV/LyU1q1t1btS6K3vJrSW6nH7ACap+wtO4AmIexAEKWE3cxuNbNDZvaemT1YRg/VmNlhM3vLzA6UPT5dNobeMTM7OGZam5m9aGbvZs/jjrFXUm8Pmdlgtu4OmNntJfU2x8z2mNmAmb1tZquy6aWuu0RfTVlvTT9mN7Mpkv4oaamkI5JeldTl7gNNbaQKMzssaZG7l/4DDDP7B0mnJG0+N7SWmf2LpOPuvi77j3Kmu/+8RXp7SOc5jHeDeqs2zPhPVOK6K3L48zzK2LIvlvSeu7/v7mck/VbSshL6aHnuvlfS8a9MXiZpU/Z6kyr/WJquSm8twd2H3H1/9vqkpHPDjJe67hJ9NUUZYZ8t6U9j3h9Ra4337pJ2mtlrZtZddjPjaB8zzNaHktrLbGYcNYfxbqavDDPeMusuz/Dn9eIE3dctcfe/lXSbpJXZ7mpL8soxWCtdO/2lpPmqjAE4JGl9mc1kw4w/K+ln7n5ibK3MdTdOX01Zb2WEfVDSnDHvv51NawnuPpg9H5P0vCqHHa3k6LkRdLPnYyX38yV3P+ruZ919VNKvVOK6y4YZf1bSb9z9uWxy6etuvL6atd7KCPurkq40s++Y2VRJP5K0rYQ+vsbMpmUnTmRm0yT9QK03FPU2Scuz18slbS2xl7/QKsN4VxtmXCWvu9KHP3f3pj8k3a7KGfn/lfRPZfRQpa95kt7IHm+X3ZukLars1v2fKuc2Vkj6a0m7JL0r6T8ltbVQb/+uytDeb6oSrFkl9bZElV30NyUdyB63l73uEn01Zb3xc1kgCE7QAUEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "\n",
    "# Log type\n",
    "print(img.view(28,28).type())\n",
    "\n",
    "# Show sample\n",
    "pretty_log(\"Image sample\")\n",
    "plt.imshow(img.view((28,28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqAiTVxDl2un"
   },
   "source": [
    "\n",
    "   \n",
    "    \n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA1rAkJi-Sfc"
   },
   "source": [
    "## **Initial Model**\n",
    "\n",
    "Let's start with some random initialisation values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ulC5Tmay-eLx"
   },
   "outputs": [],
   "source": [
    "weights = torch.randn(784,10)\n",
    "bias = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isJ_orQm-sgK"
   },
   "source": [
    "### **Matrix Multiplication**\n",
    "And now we can begin with our matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejMW3FuY-jps"
   },
   "outputs": [],
   "source": [
    "def matrix_mul(a, b):\n",
    "  a_rows, a_cols = a.shape\n",
    "  b_rows, b_cols = b.shape\n",
    "\n",
    "  # First check that multiplication is possible\n",
    "  assert a_cols == b_rows\n",
    "\n",
    "  # And then update a pytorch tensor from zeros\n",
    "  c = torch.zeros(a_rows, b_cols)\n",
    "\n",
    "  for i in range(a_rows):\n",
    "    for j in range(b_cols):\n",
    "      for k in range(a_cols): # can also be b_rows\n",
    "        c[i, j] += a[i, k] * b[k, j]\n",
    "  \n",
    "  return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiA1ySxWe3ar"
   },
   "source": [
    "From here we can test against the upcoming weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAzWqnNoe8wW",
    "outputId": "e05d2b05-e174-45d4-c82a-793be2a75307"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = x_valid[:5]\n",
    "m2 = weights\n",
    "\n",
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqgUFWy7e9kx",
    "outputId": "1ee60147-a3f7-42ab-8a83-47284ddcc578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 694 ms, sys: 678 µs, total: 695 ms\n",
      "Wall time: 706 ms\n"
     ]
    }
   ],
   "source": [
    "%time t1 = matrix_mul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BnXb-Abk7cE",
    "outputId": "de851dfe-d72f-4eb6-c44e-3cf619ffe07d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BP-A3x_lNRe"
   },
   "source": [
    "The multiplication works, but it's pretty slow (running on `O(n^2.m)`). We can speed it up using element-wise operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cPSLXoClYU9"
   },
   "source": [
    "### **Element-wise Ops**\n",
    "\n",
    "Operators (+,-,*,/,>,<,==) are usually element-wise. This is helpful because Python is slow (very slow!), and in order to perform operations which are computationally intensive we need to call Pytorch methods which are lower level (FFI or Cython?). This can be accomplished by making operations happen in an element-wise fashion.\n",
    "\n",
    "Examples of element-wise operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIhF1OxjmCj5",
    "outputId": "1ba2cc7c-e798-465f-b29f-a71008454387"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([10., 6, -4])\n",
    "b = tensor([2., 8, 7])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYW7wKNamEXg",
    "outputId": "9b46cfa9-81c6-4f0d-d810-c83c73924a71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 14.,  3.])"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LB-PfsrxmG99",
    "outputId": "b9d294af-0186-44f7-dc74-f3bd3146d8ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a < b).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X72wsOWBmI75",
    "outputId": "82bc060b-7eed-46d7-87f4-abe95976e146"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zzods9Goueo"
   },
   "source": [
    "#### **Frobenius Norm**\n",
    "\n",
    "$\\|A\\|_\\text{F} = \\sqrt{\\sum_{i,j=1}^n |a_{ij}|^2}$\n",
    "\n",
    "The Frobenius norm crops up semi-regularly in deep learning literature. It's a formula which performs element-wise multiplication for each element in a  matrix (in this case $R^2$) and takes the form of the above equation.\n",
    "\n",
    "Although it looks scary, the formula can be implemented trivially in code as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4KwUJalCqCKZ"
   },
   "outputs": [],
   "source": [
    "a_f = (m*m).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6id5sIMqg6V"
   },
   "source": [
    "We can use this to reduce the number of computationally intensive loops that need to be performed in our multiplication. Now we can multiply the full axes together (row * col) to get a $R^1$ tensor we can sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ebxlMohXqnKo"
   },
   "outputs": [],
   "source": [
    "def matrix_mul(a, b):\n",
    "  a_rows, a_cols = a.shape\n",
    "  b_rows, b_cols = b.shape\n",
    "\n",
    "  assert a_cols == b_rows\n",
    "  c = torch.zeros(a_rows, b_cols)\n",
    "\n",
    "  for i in range(a_rows):\n",
    "    for j in range(b_cols):\n",
    "      c[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "  \n",
    "  return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wksfFseDrVL3"
   },
   "source": [
    "Notice the change of `k` value to the full axis in the multiplication step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFcXaauwraaI",
    "outputId": "e233e03a-2e4b-429e-b157-63be6856a729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 1.08 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matrix_mul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2UC_Q1UsMv7"
   },
   "source": [
    "And check the speed! A huge boost in performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osxzmzpvkbeG"
   },
   "source": [
    "#### **Broadcasting**\n",
    "\n",
    "The term **broadcasting** describes how arrays with different shapes are treated during arithmetic operations. The term broadcasting was first used by Numpy.\n",
    "\n",
    "From the [Numpy documentation](https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html):\n",
    "\n",
    "> The term broadcasting describes how numpy treats arrays with \n",
    "different shapes during arithmetic operations. Subject to certain \n",
    "constraints, the smaller array is “broadcast” across the larger \n",
    "array so that they have compatible shapes. Broadcasting provides a \n",
    "means of vectorizing array operations so that looping occurs in C\n",
    "instead of Python. It does this without making needless copies of \n",
    "data and usually leads to efficient algorithm implementations.\n",
    "\n",
    "Broadcasting arithmetic operations with a $m$-dimensional array can be performed with a scalar, for example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFUcRHyflJEs",
    "outputId": "ec85b0c7-7d0d-4f29-b215-7154a67a5207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m#==== m-dimensional array ====#\u001b[0m\n",
      "\n",
      "[1 2 3]\n",
      "\n",
      "\u001b[34m#==== scalar ====#\u001b[0m\n",
      "\n",
      "2\n",
      "\n",
      "\u001b[34m#==== broadcasting result ====#\u001b[0m\n",
      "\n",
      "[3 4 5]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "a = array([1, 2, 3])\n",
    "pretty_log(\"m-dimensional array\")\n",
    "print(a)\n",
    "\n",
    "b = 2\n",
    "pretty_log(\"scalar\")\n",
    "print(b)\n",
    "\n",
    "# This will work via broadcasting\n",
    "c = a + b\n",
    "pretty_log(\"broadcasting result\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jsYyD0Ulsz5"
   },
   "source": [
    "The reason it works is that when performing the operation, the scalar `b` is multiplied in the first dimension so it has the same number of entries as `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMdnI60kl35L"
   },
   "outputs": [],
   "source": [
    "# Given vector a\n",
    "a = [a1, a2, a3]\n",
    "\n",
    "# Given scalar b\n",
    "b\n",
    "\n",
    "# Scalar b becomes vector b in broadcasting, through duplication\n",
    "b = [b1, b2, b3]\n",
    "\n",
    "# The 2 vectors can then be operated on directly\n",
    "c = a + b\n",
    "c = [a1 + b1, a2 + b2, a3 + b3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ez70xRPymKVs"
   },
   "source": [
    "#### **Broadcast Limitations**\n",
    "\n",
    "Arithmetic, including broadcasting, can only be performed when:\n",
    "\n",
    "*   the shape of each dimension in the arrays are equal, or\n",
    "*   one of them has the dimension size of 1\n",
    "\n",
    "The dimensions are considered in reverse order, starting with the trailing dimension; for example, looking at columns before rows in a two-dimensional case.\n",
    "\n",
    "Therefore, the comparison between a 2-dimensional array `A` with 2 rows and 3 columns and a vector `b` with 3 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkmCmzMQmuKX",
    "outputId": "bfdf70c6-a3d2-49ed-f776-f7a1ac215ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "A = array([[0, 0, 0],\n",
    "           [0, 0, 0]])\n",
    "\n",
    "b = array([0, 0, 0])\n",
    "\n",
    "print(A.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIvgz6wRm9Br"
   },
   "source": [
    "is considered as (note the last shape entry, the column, considered):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WShJ3MeynE6y"
   },
   "outputs": [],
   "source": [
    "# A.shape = (2 x 3)\n",
    "# b.shape = (1 x 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRSrZHy7nWVA"
   },
   "source": [
    "This is also okay with a scalar, since it's a 1-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMnTcbC7ncJK"
   },
   "outputs": [],
   "source": [
    "# A.shape = (2 x 3)\n",
    "# b.shape = (1) or (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL3yhPmDnfY3"
   },
   "source": [
    "But the following will throw an error, due to mismatched columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxldKakSn_I4",
    "outputId": "5f441e57-3d1c-4dcd-b8b1-7224dd4c0487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m#==== These arrays cannot be broadcast due to their shape ====#\u001b[0m\n",
      "\n",
      "(2, 3)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "# A.shape = (2 x 3)\n",
    "A = array([[0, 0, 0],\n",
    "           [0, 0, 0]])\n",
    "\n",
    "# b.shape = (1 x 2)\n",
    "b = array([0, 0])\n",
    "\n",
    "try:\n",
    "  C = A + b\n",
    "except ValueError:\n",
    "  pretty_log(\"These arrays cannot be broadcast due to their shape\", \"error\")\n",
    "  print(A.shape)\n",
    "  print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogtsbhh5sk5v"
   },
   "source": [
    "#### **A Note on Dimensional Manipulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMOV5xOWrvpc"
   },
   "source": [
    "We can manipulate the dimensions of a Numpy array be using `squeeze` and `unsqueeze`, which will reduce or add dimensions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ym5ziX8Gr5_D",
    "outputId": "74c3f738-a328-40b7-9e99-fa0b6efffb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 20., 30.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "c = tensor([10.,20,30])\n",
    "\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VElgNlSCr_HG",
    "outputId": "799f5faf-9ff7-4f0d-fcda-b4cf642618dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10., 20., 30.]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "d = c.unsqueeze(0)\n",
    "\n",
    "print(d)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raBp0jqwsOfz",
    "outputId": "ff2ade7e-bd04-4c7d-8d67-377d3c67150a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.],\n",
      "        [20.],\n",
      "        [30.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "e = c.unsqueeze(1)\n",
    "\n",
    "print(e)\n",
    "print(e.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4fXCk9ytHsz"
   },
   "source": [
    "Using the methods directly is a bit unwieldy, so Pytorch includes a shorthand to perform them inline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L03ggEhKtQ1v",
    "outputId": "eb6a2660-91a9-490d-ed03-3b06a7b2ce68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c.unsqueeze(0).shape,c.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkIjrXF8tZ4v"
   },
   "source": [
    "This is done using the `None` keyword in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwbZeo6Ytd4r",
    "outputId": "f412c22a-8b94-423c-f468-46b47f282b95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c[None].shape,c[:,None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsDRTFB_pr1v"
   },
   "source": [
    "#### **Matrix_mul with broadcasting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Jzev3ouXpzHm"
   },
   "outputs": [],
   "source": [
    "def matrix_mul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "\n",
    "    for i in range(ar):\n",
    "       #c[i,j] = (a[i,:] * b[:,j]).sum() # previous\n",
    "        c[i,:] = (a[i  ].unsqueeze(-1) * b).sum(dim=0)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ehImDNhqI8E",
    "outputId": "842a0117-3be5-4eb4-ec6e-9ccf25357ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 219 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matrix_mul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyMiutJcxHZd"
   },
   "source": [
    "### **Einsten Summation**\n",
    "\n",
    "Einstein summation (`einsum`) is a compact representation/notation for combining products and sums in a general way. From the [Numpy docs](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html):\n",
    "\n",
    "> The subscripts string is a comma-separated list of subscript labels, where each label refers to a dimension of the corresponding operand. Whenever a label is repeated it is summed, so np.einsum('i,i', a, b) is equivalent to np.inner(a,b). If a label appears only once, it is not summed, so np.einsum('i', a) produces a view of a with no changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "RCcvr2eoyHlG"
   },
   "outputs": [],
   "source": [
    "# c[i,j] += a[i,k] * b[k,j]\n",
    "# c[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "def matrix_mul(a,b): return torch.einsum('ik,kj->ij', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "z7TTeMNrybw6",
    "outputId": "bc14a364-f39c-4e00-a512-f3c166d9bbb4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'torch.ByteTensor'"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Byte tensor\n",
    "m2 = m2.byte()\n",
    "m2.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnEJRirDyMFi",
    "outputId": "7824c26f-a751-4f04-96a8-b5046ab168db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 63.2 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matrix_mul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilczqnpYy3_u"
   },
   "source": [
    "### **Pytorch op**\n",
    "\n",
    "Finally, we can use Pytorch's function or operator directly for matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ClYeeX_czCsj",
    "outputId": "9b862e28-0aa3-4d72-d88a-d508dd1c0fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 48.3 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 t2 = m1.matmul(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xl7LNiJHzFaS",
    "outputId": "522a123f-6904-42ce-816d-076ca28fc954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6zq_S_8zN5Y"
   },
   "source": [
    "It's also possible to use the shorthand for this operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEoDK4GOzQ4P",
    "outputId": "d28af4cb-7028-430e-eced-25913c2b5019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 47.3 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 t2 = m1@m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd_dnwHoz-lr"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LQAUnFHz4UL"
   },
   "source": [
    "## **Exports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liZuEzorz9Rk"
   },
   "outputs": [],
   "source": [
    "!python notebook2script.py 01_matrix-mul.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01_matrix-mul.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
